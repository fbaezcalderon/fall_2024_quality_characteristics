{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk # Natural Languaje Tool Kit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df = pd.read_csv('Greenis.csv', delimiter=',') # read csv file and create a pandas dataframa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(632, 5)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df.shape # Check for shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5 colums and 632 rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "      <th>original_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>addictive! but works for night coughing in dogs</td>\n",
       "      <td>my 12 year old sheltie has chronic brochotitis...</td>\n",
       "      <td>my 12 year old sheltie has chronic brochotitis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>genuine greenies best price</td>\n",
       "      <td>these are genuine greenies product not a knock...</td>\n",
       "      <td>these are genuine greenies product not a knock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>perfect for our little doggies</td>\n",
       "      <td>our dogs love greenies but of course which dog...</td>\n",
       "      <td>our dogs love greenies but of course which dog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>dogs love greenies</td>\n",
       "      <td>what can i say dogs love greenies they begg fo...</td>\n",
       "      <td>what can i say dogs love greenies they begg fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>greenies review</td>\n",
       "      <td>this review is for a box of greenies lite for ...</td>\n",
       "      <td>this review is for a box of greenies lite for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                          Summary  \\\n",
       "0      5  addictive! but works for night coughing in dogs   \n",
       "1      5                      genuine greenies best price   \n",
       "2      5                   perfect for our little doggies   \n",
       "3      5                               dogs love greenies   \n",
       "4      5                                  greenies review   \n",
       "\n",
       "                                                Text  \\\n",
       "0  my 12 year old sheltie has chronic brochotitis...   \n",
       "1  these are genuine greenies product not a knock...   \n",
       "2  our dogs love greenies but of course which dog...   \n",
       "3  what can i say dogs love greenies they begg fo...   \n",
       "4  this review is for a box of greenies lite for ...   \n",
       "\n",
       "                                       original_text  \n",
       "0  my 12 year old sheltie has chronic brochotitis...  \n",
       "1  these are genuine greenies product not a knock...  \n",
       "2  our dogs love greenies but of course which dog...  \n",
       "3  what can i say dogs love greenies they begg fo...  \n",
       "4  this review is for a box of greenies lite for ...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df.head() # Check dataframe head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df =  product_df[['Score','Summary','Text']].copy() # Copy dataframe with a limited number of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unnecesary columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Score', 'Summary', 'Text'], dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df.columns # Check new dataframe colum names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have been feeding our dogs greenie bones since they first came out and we have never had a problem  i have german shepards dobermans and medium sized hound dogs  they all love their gbs and i find that because our dobie tends to be a garbage belly meaning shell eat anything so sometimes she doesnt smell as nice as she should really benefits from the green in greenie bones  i would like to know where e antic gets hisher information fromas i can find nothing that says they are deadly except for those people that havent done responsible research not just hearsay from some list  if your dogs are gulpers or greedy chewers then i wouldnt feed them anything especially rawhide that could be gulped and swallowed in large pieces or whole  do we need to bring up nylabones  always be a responsible dog owner and supervise your dogs when giving any kind of treats  please dont be afraid of greenie bones because of e antics post  you can buy greenies in singles so try one before you commit to a whole box  i have friends that have dogs that dont really like them and thats okay  my girls live for their morning gbs and i now give them greenie smart biscuits for an afternoon snack  they love the taste and we love them for the benefitsbr br i respectfully request that amazon and amazon members make up their own minds and not fall to the fear mongers and ignorance amoung us  always supervise your dogs when giving treats  after all they are the animals and we are supposed to be the smart onesdont be afraid do your homework it always pays'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example =  product_df ['Text'][100]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "sia = SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#nltk.download()  # starts nltk downloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.448, 'pos': 0.552, 'compound': 0.5719}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores('This is a perfect evening') # Calcluate polarity scores for a positive sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.6, 'neu': 0.4, 'pos': 0.0, 'compound': -0.4588}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores('This is awful') # Calcluate polarity scores for a negative sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i have been feeding our dogs greenie bones since they first came out and we have never had a problem  i have german shepards dobermans and medium sized hound dogs  they all love their gbs and i find that because our dobie tends to be a garbage belly meaning shell eat anything so sometimes she doesnt smell as nice as she should really benefits from the green in greenie bones  i would like to know where e antic gets hisher information fromas i can find nothing that says they are deadly except for those people that havent done responsible research not just hearsay from some list  if your dogs are gulpers or greedy chewers then i wouldnt feed them anything especially rawhide that could be gulped and swallowed in large pieces or whole  do we need to bring up nylabones  always be a responsible dog owner and supervise your dogs when giving any kind of treats  please dont be afraid of greenie bones because of e antics post  you can buy greenies in singles so try one before you commit to a whole box  i have friends that have dogs that dont really like them and thats okay  my girls live for their morning gbs and i now give them greenie smart biscuits for an afternoon snack  they love the taste and we love them for the benefitsbr br i respectfully request that amazon and amazon members make up their own minds and not fall to the fear mongers and ignorance amoung us  always supervise your dogs when giving treats  after all they are the animals and we are supposed to be the smart onesdont be afraid do your homework it always pays'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens =  nltk.word_tokenize(example) # Create a list of tokens, (Divide text in words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'have',\n",
       " 'been',\n",
       " 'feeding',\n",
       " 'our',\n",
       " 'dogs',\n",
       " 'greenie',\n",
       " 'bones',\n",
       " 'since',\n",
       " 'they',\n",
       " 'first',\n",
       " 'came',\n",
       " 'out',\n",
       " 'and',\n",
       " 'we',\n",
       " 'have',\n",
       " 'never',\n",
       " 'had',\n",
       " 'a',\n",
       " 'problem',\n",
       " 'i',\n",
       " 'have',\n",
       " 'german',\n",
       " 'shepards',\n",
       " 'dobermans',\n",
       " 'and',\n",
       " 'medium',\n",
       " 'sized',\n",
       " 'hound',\n",
       " 'dogs',\n",
       " 'they',\n",
       " 'all',\n",
       " 'love',\n",
       " 'their',\n",
       " 'gbs',\n",
       " 'and',\n",
       " 'i',\n",
       " 'find',\n",
       " 'that',\n",
       " 'because',\n",
       " 'our',\n",
       " 'dobie',\n",
       " 'tends',\n",
       " 'to',\n",
       " 'be',\n",
       " 'a',\n",
       " 'garbage',\n",
       " 'belly',\n",
       " 'meaning',\n",
       " 'shell',\n",
       " 'eat',\n",
       " 'anything',\n",
       " 'so',\n",
       " 'sometimes',\n",
       " 'she',\n",
       " 'doesnt',\n",
       " 'smell',\n",
       " 'as',\n",
       " 'nice',\n",
       " 'as',\n",
       " 'she',\n",
       " 'should',\n",
       " 'really',\n",
       " 'benefits',\n",
       " 'from',\n",
       " 'the',\n",
       " 'green',\n",
       " 'in',\n",
       " 'greenie',\n",
       " 'bones',\n",
       " 'i',\n",
       " 'would',\n",
       " 'like',\n",
       " 'to',\n",
       " 'know',\n",
       " 'where',\n",
       " 'e',\n",
       " 'antic',\n",
       " 'gets',\n",
       " 'hisher',\n",
       " 'information',\n",
       " 'fromas',\n",
       " 'i',\n",
       " 'can',\n",
       " 'find',\n",
       " 'nothing',\n",
       " 'that',\n",
       " 'says',\n",
       " 'they',\n",
       " 'are',\n",
       " 'deadly',\n",
       " 'except',\n",
       " 'for',\n",
       " 'those',\n",
       " 'people',\n",
       " 'that',\n",
       " 'havent',\n",
       " 'done',\n",
       " 'responsible',\n",
       " 'research',\n",
       " 'not',\n",
       " 'just',\n",
       " 'hearsay',\n",
       " 'from',\n",
       " 'some',\n",
       " 'list',\n",
       " 'if',\n",
       " 'your',\n",
       " 'dogs',\n",
       " 'are',\n",
       " 'gulpers',\n",
       " 'or',\n",
       " 'greedy',\n",
       " 'chewers',\n",
       " 'then',\n",
       " 'i',\n",
       " 'wouldnt',\n",
       " 'feed',\n",
       " 'them',\n",
       " 'anything',\n",
       " 'especially',\n",
       " 'rawhide',\n",
       " 'that',\n",
       " 'could',\n",
       " 'be',\n",
       " 'gulped',\n",
       " 'and',\n",
       " 'swallowed',\n",
       " 'in',\n",
       " 'large',\n",
       " 'pieces',\n",
       " 'or',\n",
       " 'whole',\n",
       " 'do',\n",
       " 'we',\n",
       " 'need',\n",
       " 'to',\n",
       " 'bring',\n",
       " 'up',\n",
       " 'nylabones',\n",
       " 'always',\n",
       " 'be',\n",
       " 'a',\n",
       " 'responsible',\n",
       " 'dog',\n",
       " 'owner',\n",
       " 'and',\n",
       " 'supervise',\n",
       " 'your',\n",
       " 'dogs',\n",
       " 'when',\n",
       " 'giving',\n",
       " 'any',\n",
       " 'kind',\n",
       " 'of',\n",
       " 'treats',\n",
       " 'please',\n",
       " 'dont',\n",
       " 'be',\n",
       " 'afraid',\n",
       " 'of',\n",
       " 'greenie',\n",
       " 'bones',\n",
       " 'because',\n",
       " 'of',\n",
       " 'e',\n",
       " 'antics',\n",
       " 'post',\n",
       " 'you',\n",
       " 'can',\n",
       " 'buy',\n",
       " 'greenies',\n",
       " 'in',\n",
       " 'singles',\n",
       " 'so',\n",
       " 'try',\n",
       " 'one',\n",
       " 'before',\n",
       " 'you',\n",
       " 'commit',\n",
       " 'to',\n",
       " 'a',\n",
       " 'whole',\n",
       " 'box',\n",
       " 'i',\n",
       " 'have',\n",
       " 'friends',\n",
       " 'that',\n",
       " 'have',\n",
       " 'dogs',\n",
       " 'that',\n",
       " 'dont',\n",
       " 'really',\n",
       " 'like',\n",
       " 'them',\n",
       " 'and',\n",
       " 'thats',\n",
       " 'okay',\n",
       " 'my',\n",
       " 'girls',\n",
       " 'live',\n",
       " 'for',\n",
       " 'their',\n",
       " 'morning',\n",
       " 'gbs',\n",
       " 'and',\n",
       " 'i',\n",
       " 'now',\n",
       " 'give',\n",
       " 'them',\n",
       " 'greenie',\n",
       " 'smart',\n",
       " 'biscuits',\n",
       " 'for',\n",
       " 'an',\n",
       " 'afternoon',\n",
       " 'snack',\n",
       " 'they',\n",
       " 'love',\n",
       " 'the',\n",
       " 'taste',\n",
       " 'and',\n",
       " 'we',\n",
       " 'love',\n",
       " 'them',\n",
       " 'for',\n",
       " 'the',\n",
       " 'benefitsbr',\n",
       " 'br',\n",
       " 'i',\n",
       " 'respectfully',\n",
       " 'request',\n",
       " 'that',\n",
       " 'amazon',\n",
       " 'and',\n",
       " 'amazon',\n",
       " 'members',\n",
       " 'make',\n",
       " 'up',\n",
       " 'their',\n",
       " 'own',\n",
       " 'minds',\n",
       " 'and',\n",
       " 'not',\n",
       " 'fall',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fear',\n",
       " 'mongers',\n",
       " 'and',\n",
       " 'ignorance',\n",
       " 'amoung',\n",
       " 'us',\n",
       " 'always',\n",
       " 'supervise',\n",
       " 'your',\n",
       " 'dogs',\n",
       " 'when',\n",
       " 'giving',\n",
       " 'treats',\n",
       " 'after',\n",
       " 'all',\n",
       " 'they',\n",
       " 'are',\n",
       " 'the',\n",
       " 'animals',\n",
       " 'and',\n",
       " 'we',\n",
       " 'are',\n",
       " 'supposed',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " 'smart',\n",
       " 'onesdont',\n",
       " 'be',\n",
       " 'afraid',\n",
       " 'do',\n",
       " 'your',\n",
       " 'homework',\n",
       " 'it',\n",
       " 'always',\n",
       " 'pays']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'NNS'),\n",
       " ('have', 'VBP'),\n",
       " ('been', 'VBN'),\n",
       " ('feeding', 'VBG'),\n",
       " ('our', 'PRP$'),\n",
       " ('dogs', 'NNS'),\n",
       " ('greenie', 'VBP'),\n",
       " ('bones', 'NNS'),\n",
       " ('since', 'IN'),\n",
       " ('they', 'PRP'),\n",
       " ('first', 'RB'),\n",
       " ('came', 'VBD'),\n",
       " ('out', 'RB'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('have', 'VBP'),\n",
       " ('never', 'RB'),\n",
       " ('had', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('problem', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('have', 'VBP'),\n",
       " ('german', 'JJ'),\n",
       " ('shepards', 'NNS'),\n",
       " ('dobermans', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('medium', 'NN'),\n",
       " ('sized', 'VBN'),\n",
       " ('hound', 'JJ'),\n",
       " ('dogs', 'NNS'),\n",
       " ('they', 'PRP'),\n",
       " ('all', 'DT'),\n",
       " ('love', 'VBP'),\n",
       " ('their', 'PRP$'),\n",
       " ('gbs', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('i', 'NN'),\n",
       " ('find', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('because', 'IN'),\n",
       " ('our', 'PRP$'),\n",
       " ('dobie', 'NN'),\n",
       " ('tends', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('garbage', 'NN'),\n",
       " ('belly', 'RB'),\n",
       " ('meaning', 'VBG'),\n",
       " ('shell', 'NN'),\n",
       " ('eat', 'NN'),\n",
       " ('anything', 'NN'),\n",
       " ('so', 'RB'),\n",
       " ('sometimes', 'RB'),\n",
       " ('she', 'PRP'),\n",
       " ('doesnt', 'VBZ'),\n",
       " ('smell', 'RB'),\n",
       " ('as', 'RB'),\n",
       " ('nice', 'JJ'),\n",
       " ('as', 'IN'),\n",
       " ('she', 'PRP'),\n",
       " ('should', 'MD'),\n",
       " ('really', 'RB'),\n",
       " ('benefits', 'NNS'),\n",
       " ('from', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('green', 'JJ'),\n",
       " ('in', 'IN'),\n",
       " ('greenie', 'JJ'),\n",
       " ('bones', 'NNS'),\n",
       " ('i', 'RB'),\n",
       " ('would', 'MD'),\n",
       " ('like', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('know', 'VB'),\n",
       " ('where', 'WRB'),\n",
       " ('e', 'JJ'),\n",
       " ('antic', 'JJ'),\n",
       " ('gets', 'VBZ'),\n",
       " ('hisher', 'PRP$'),\n",
       " ('information', 'NN'),\n",
       " ('fromas', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('can', 'MD'),\n",
       " ('find', 'VB'),\n",
       " ('nothing', 'NN'),\n",
       " ('that', 'WDT'),\n",
       " ('says', 'VBZ'),\n",
       " ('they', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('deadly', 'RB'),\n",
       " ('except', 'IN'),\n",
       " ('for', 'IN'),\n",
       " ('those', 'DT'),\n",
       " ('people', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('havent', 'VBP'),\n",
       " ('done', 'VBN'),\n",
       " ('responsible', 'JJ'),\n",
       " ('research', 'NN'),\n",
       " ('not', 'RB'),\n",
       " ('just', 'RB'),\n",
       " ('hearsay', 'VB'),\n",
       " ('from', 'IN'),\n",
       " ('some', 'DT'),\n",
       " ('list', 'NN'),\n",
       " ('if', 'IN'),\n",
       " ('your', 'PRP$'),\n",
       " ('dogs', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('gulpers', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('greedy', 'NN'),\n",
       " ('chewers', 'NNS'),\n",
       " ('then', 'RB'),\n",
       " ('i', 'VBP'),\n",
       " ('wouldnt', 'VBP'),\n",
       " ('feed', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " ('anything', 'NN'),\n",
       " ('especially', 'RB'),\n",
       " ('rawhide', 'VBP'),\n",
       " ('that', 'DT'),\n",
       " ('could', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('gulped', 'VBN'),\n",
       " ('and', 'CC'),\n",
       " ('swallowed', 'VBN'),\n",
       " ('in', 'IN'),\n",
       " ('large', 'JJ'),\n",
       " ('pieces', 'NNS'),\n",
       " ('or', 'CC'),\n",
       " ('whole', 'JJ'),\n",
       " ('do', 'VBP'),\n",
       " ('we', 'PRP'),\n",
       " ('need', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('bring', 'VB'),\n",
       " ('up', 'RP'),\n",
       " ('nylabones', 'NNS'),\n",
       " ('always', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('responsible', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('owner', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('supervise', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('dogs', 'NNS'),\n",
       " ('when', 'WRB'),\n",
       " ('giving', 'VBG'),\n",
       " ('any', 'DT'),\n",
       " ('kind', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('treats', 'NNS'),\n",
       " ('please', 'VBP'),\n",
       " ('dont', 'JJ'),\n",
       " ('be', 'VB'),\n",
       " ('afraid', 'VBN'),\n",
       " ('of', 'IN'),\n",
       " ('greenie', 'NN'),\n",
       " ('bones', 'NNS'),\n",
       " ('because', 'IN'),\n",
       " ('of', 'IN'),\n",
       " ('e', 'NN'),\n",
       " ('antics', 'NNS'),\n",
       " ('post', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('can', 'MD'),\n",
       " ('buy', 'VB'),\n",
       " ('greenies', 'NNS'),\n",
       " ('in', 'IN'),\n",
       " ('singles', 'NNS'),\n",
       " ('so', 'RB'),\n",
       " ('try', 'VB'),\n",
       " ('one', 'CD'),\n",
       " ('before', 'IN'),\n",
       " ('you', 'PRP'),\n",
       " ('commit', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('a', 'DT'),\n",
       " ('whole', 'JJ'),\n",
       " ('box', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('have', 'VBP'),\n",
       " ('friends', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('have', 'VBP'),\n",
       " ('dogs', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('dont', 'VBP'),\n",
       " ('really', 'RB'),\n",
       " ('like', 'IN'),\n",
       " ('them', 'PRP'),\n",
       " ('and', 'CC'),\n",
       " ('thats', 'VB'),\n",
       " ('okay', 'JJ'),\n",
       " ('my', 'PRP$'),\n",
       " ('girls', 'NNS'),\n",
       " ('live', 'VBP'),\n",
       " ('for', 'IN'),\n",
       " ('their', 'PRP$'),\n",
       " ('morning', 'NN'),\n",
       " ('gbs', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('i', 'NN'),\n",
       " ('now', 'RB'),\n",
       " ('give', 'VBP'),\n",
       " ('them', 'PRP'),\n",
       " ('greenie', 'JJS'),\n",
       " ('smart', 'JJ'),\n",
       " ('biscuits', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('an', 'DT'),\n",
       " ('afternoon', 'NN'),\n",
       " ('snack', 'NN'),\n",
       " ('they', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('taste', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('them', 'PRP'),\n",
       " ('for', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('benefitsbr', 'NN'),\n",
       " ('br', 'NN'),\n",
       " ('i', 'NN'),\n",
       " ('respectfully', 'RB'),\n",
       " ('request', 'VBP'),\n",
       " ('that', 'IN'),\n",
       " ('amazon', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('amazon', 'JJ'),\n",
       " ('members', 'NNS'),\n",
       " ('make', 'VBP'),\n",
       " ('up', 'RP'),\n",
       " ('their', 'PRP$'),\n",
       " ('own', 'JJ'),\n",
       " ('minds', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('not', 'RB'),\n",
       " ('fall', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('the', 'DT'),\n",
       " ('fear', 'NN'),\n",
       " ('mongers', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('ignorance', 'NN'),\n",
       " ('amoung', 'VBP'),\n",
       " ('us', 'PRP'),\n",
       " ('always', 'RB'),\n",
       " ('supervise', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('dogs', 'NNS'),\n",
       " ('when', 'WRB'),\n",
       " ('giving', 'VBG'),\n",
       " ('treats', 'NNS'),\n",
       " ('after', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('they', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('the', 'DT'),\n",
       " ('animals', 'NNS'),\n",
       " ('and', 'CC'),\n",
       " ('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('supposed', 'VBN'),\n",
       " ('to', 'TO'),\n",
       " ('be', 'VB'),\n",
       " ('the', 'DT'),\n",
       " ('smart', 'JJ'),\n",
       " ('onesdont', 'NN'),\n",
       " ('be', 'VB'),\n",
       " ('afraid', 'JJ'),\n",
       " ('do', 'VB'),\n",
       " ('your', 'PRP$'),\n",
       " ('homework', 'NN'),\n",
       " ('it', 'PRP'),\n",
       " ('always', 'RB'),\n",
       " ('pays', 'VBZ')]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(tokens) # Asign tags to tokens (Clasify in vebs, adverbs, nouns, etc. )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df['Text'] = product_df['Text'].str.lower()\n",
    "product_df['Summary']= product_df['Summary'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>addictive! but works for night coughing in dogs</td>\n",
       "      <td>my 12 year old sheltie has chronic brochotitis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>genuine greenies best price</td>\n",
       "      <td>these are genuine greenies product not a knock...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>perfect for our little doggies</td>\n",
       "      <td>our dogs love greenies but of course which dog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>dogs love greenies</td>\n",
       "      <td>what can i say dogs love greenies they begg fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>greenies review</td>\n",
       "      <td>this review is for a box of greenies lite for ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Score                                          Summary  \\\n",
       "0      5  addictive! but works for night coughing in dogs   \n",
       "1      5                      genuine greenies best price   \n",
       "2      5                   perfect for our little doggies   \n",
       "3      5                               dogs love greenies   \n",
       "4      5                                  greenies review   \n",
       "\n",
       "                                                Text  \n",
       "0  my 12 year old sheltie has chronic brochotitis...  \n",
       "1  these are genuine greenies product not a knock...  \n",
       "2  our dogs love greenies but of course which dog...  \n",
       "3  what can i say dogs love greenies they begg fo...  \n",
       "4  this review is for a box of greenies lite for ...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "product_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "translator =  str.maketrans('','',string.punctuation)\n",
    "product_df['Text'] = product_df['Text'].str.translate(translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stpo words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = product_df['Text'][200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.765, 'pos': 0.235, 'compound': 0.8402}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sia.polarity_scores(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\fabia\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_df['original_text'] =  product_df['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "## new line\n",
    "for i in range(20):\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uxs24",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
